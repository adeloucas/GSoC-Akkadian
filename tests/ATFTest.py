__author__ = ['Andrew Deloucas <ADeloucas@g.harvard.com>']
__license__ = 'MIT License. See LICENSE.'

import unittest
from ATFConverter.ATFConverter import ATFConverter
from ATFConverter.Tokenizer import Tokenizer

class test1(unittest.TestCase):  # pylint: disable=R0904

    def test_convert_tittles(self):
        ATF = ATFConverter()
        signs = str([(r'as,'), (r'S,ATU'), (r'tet,'), (r'T,et'), (r'sza'), (r'ASZ')])
        target = str(['aá¹£', 'á¹¢ATU', 'teá¹­', 'á¹¬et', 'Å¡a', 'AÅ '])
        output = ATF.convert_consonant(signs)
        self.assertEqual(output, target)

    def test_get_number_from_sign(self):
        ATF = ATFConverter()
        signs = ["a", "a1", "be2", "bad3", "buru14"]
        target = [0, 1, 2, 3, 14]

        output = [ATF.get_number_from_sign(s)[1] for s in signs]

        self.assertEqual(output, target)

    def test_single_sign(self):
        ATF = ATFConverter(two_three=True)
        signs = ["a", "a1", "a2", "a3", "be2", "be3", "bad2", "bad3"]
        target = ["a", "a", "aâ‚‚", "aâ‚ƒ", "beâ‚‚", "beâ‚ƒ", "badâ‚‚", "badâ‚ƒ"]

        output = ATF.process(signs)

        self.assertEqual(output, target)

    def test_accents(self):
        ATF = ATFConverter(two_three=False)
        signs = ["a", "a2", "a3", "be2", "bad3", "buru14"]
        target = ["a", "Ã¡", "Ã ", "bÃ©", "bÃ d", "buruâ‚â‚„"]

        output = ATF.process(signs)

        self.assertEqual(output, target)

    def test_unknown_token(self):
        ATF = ATFConverter(two_three=True)
        signs = ["a2", "â˜‰", "be3"]
        target = ["aâ‚‚", "â˜‰", "beâ‚ƒ"]

        output = ATF.process(signs)

        self.assertEqual(output, target)

    def test_determinatives(self):
        ATF = ATFConverter()
        text = str(['{d}', '{iri}', '{lÃº}', '{lu2}', '{diÅ¡}', '{disz}', '{geÅ¡}', '{gesz}', '{munus}', '{Å¡e}', 
                '{sze}', '{uzu}', '{kuÅ¡}', '{kusz}', '{ki}', r'(u)', r'(diÅ¡)', r'(disz)', r'{i7}', r'{I7}'])
        target = str(['áµˆ', 'â±Ê³â±', 'Ë¡á¶¸Â²', 'Ë¡á¶¸Â²', 'ğ’¹', 'ğ’¹', 'áµáµ‰Ë¢á¶»', 'áµáµ‰Ë¢á¶»', 'áµá¶¸â¿á¶¸Ë¢', 'Ë¢á¶»áµ‰',
                      'Ë¢á¶»áµ‰', 'á¶¸á¶»á¶¸', 'áµá¶¸Ë¢á¶»', 'áµá¶¸Ë¢á¶»', 'áµâ±', '(ğ’Œ‹)', '(ğ’¹)', '(ğ’¹)','â±â·', 'â±â·'])

        output = ATF.determination(text)
        self.maxDiff = None
        self.assertEqual(output, target)

 #   def test_sumerian(self):
 #       ATF = ATFConverter()
 #       sign = ['_lugal_',  '_hÃ©-gÃ¡l_',  '_uÅ¡umgal lugal_-rÃ­',  '_Å¡e_ Ã¹ _kÃ¹-babbar_', 'lu _guâ‚„_ lu _udu_',  
 #               '_|maÅ¡.en.gag|_',  '_iti 6(ğ’¹)-kam_', #r'lu _guâ‚„_ lu _udu_ lu _anÅ¡e_ lu _Å¡Ã¡h_',
 #               'lu _Ã¡rad |maÅ¡.en.gag|_', '_a-Å¡Ã _-Å¡u Ã¹ _áµáµ‰Ë¢á¶»kiriâ‚†_-Å¡u', '_aga#-Ãºs_',  '_aga-Ãºs#_',  
 #               '_a-Å¡Ã _-Å¡u _áµáµ‰Ë¢á¶»kiriâ‚†_-Å¡u# Ã¹ _Ã©_-sÃº#', '_Ã¡b# guâ‚„!(bi) hi-a_', '_Å¡e_ Å¡a i-na _a-Å¡Ã _', 
 #               '_[a]-Å¡Ã _-Å¡u', '_a-Å¡Ã  uâ‚ˆ udu hi-a_', '_a-rÃ¡_ 3(ğ’¹)-Å¡u a-na _dam-gÃ r_', 
 #               'Å¡a _dumu-meÅ¡_ ul-du-Å¡um Ã¹ lu _lukur_ Å¡a _dumu-meÅ¡_', '_uâ‚ˆ [udu hi-a_]', 
 #               'Ã¹ lu _ur-mah_ id-du-uk _sipa_ ma-hi! _dingir_', '_Å¡e kÃ¹]-babbar_', 
 #               '_uâ‚„ 2(ğ’¹)-kam# [3(ğ’¹)-kam]_ i-na _Ã©-hi-a_-Å¡u-nu', '_iti#_', 
 #               '_[áµáµ‰Ë¢á¶»]mÃ¡# hi-a gal_ la# im#-ma#-ad-du _1(ğ’Œ‹)-kam_', '_áµáµ‰Ë¢á¶»geÅ¡immar áµáµ‰Ë¢á¶»Å¡u-Ãºr-mÃ¬n_ Ã¹ _áµáµ‰Ë¢á¶»az_', 
 #               '_a#-Å¡Ã #-hi-a_', '_2(ğ’¹) anÅ¡e gÃº_ Ã¹ _1(ğ’¹) tur [..._]', '_iti_ ti-ri-im _uâ‚„ 1(ğ’Œ‹) 5(ğ’¹)-kam ba-zal_-[ma]', 
 #               '_1(ğ’Œ‹)# gÃº# kÃ¹-sigâ‚â‚‡_', 'a-na _5(ğ’¹) Ë¡á¶¸Â²Ã¡rad-meÅ¡_ i-yu-ti-in _1(ğ’¹)-Ã m_ áµá¶¸Ë¢á¶»na-da-tim# _2(ğ’¹)-Ã m_ áµá¶¸Ë¢á¶»me-Å¡e-[ni]', 
 #               '_áµˆ#iÅ¡kur#_', '_gÃº# [kÃ¹]-babbar_ te-er-ha-at _dumu-munus_', '_inim?-áµˆiÅ¡kur#?_', 
 #               '[_Ã¡rad_] [a]-bi-im _uâ‚„ 6(ğ’¹)-kam zal_-[ma]']
 #       target = str(['_LUGAL_', '_HÃ‰-GÃL_', '_UÅ UMGAL LUGAL_-rÃ­', '_Å E_ Ã¹ _KÃ™-BABBAR_', 'lu _GUâ‚„_ lu _UDU_', 
 #               '_|MAÅ .EN.GAG|_', '_ITI 6(ğ’¹)-KAM_', #r'lu _GUâ‚„_ lu _UDU_ lu _ANÅ E_ lu _Å ÃH_',
 #               'lu _ÃRAD |MAÅ .EN.GAG|_', '_A-Å Ã€_-Å¡u Ã¹ _áµáµ‰Ë¢á¶»KIRIâ‚†_-Å¡u', '_AGA#-ÃšS_', '_AGA-ÃšS#_', 
 #               '_A-Å Ã€_-Å¡u _áµáµ‰Ë¢á¶»KIRIâ‚†_-Å¡u# Ã¹ _Ã‰_-sÃº#', '_ÃB# GUâ‚„!(BI) HI-A_',  '_Å E_ Å¡a i-na _A-Å Ã€_', 
 #               '_[A]-Å Ã€_-Å¡u',  '_A-Å Ã€ Uâ‚ˆ UDU HI-A_',  '_A-RÃ_ 3(ğ’¹)-Å¡u a-na _DAM-GÃ€R_',  
 #               'Å¡a _DUMU-MEÅ _ ul-du-Å¡um Ã¹ lu _LUKUR_ Å¡a _DUMU-MEÅ _',  '_Uâ‚ˆ [UDU HI-A_]',  
 #               'Ã¹ lu _UR-MAH_ id-du-uk _SIPA_ ma-hi! _DINGIR_',  '_Å E KÃ™]-BABBAR_', 
 #               '_Uâ‚„ 2(ğ’¹)-KAM# [3(ğ’¹)-KAM]_ i-na _Ã‰-HI-A_-Å¡u-nu',  '_ITI#_', 
 #               '_[áµáµ‰Ë¢á¶»]MÃ# HI-A GAL_ la# im#-ma#-ad-du _1(ğ’Œ‹)-KAM_', '_áµáµ‰Ë¢á¶»GEÅ IMMAR áµáµ‰Ë¢á¶»Å U-ÃšR-MÃŒN_ Ã¹ _áµáµ‰Ë¢á¶»AZ_', 
 #               '_A#-Å Ã€#-HI-A_', '_2(ğ’¹) ANÅ E GÃš_ Ã¹ _1(ğ’¹) TUR [..._]', '_ITI_ ti-ri-im _Uâ‚„ 1(ğ’Œ‹) 5(ğ’¹)-KAM BA-ZAL_-[ma]',  
 #               '_1(ğ’Œ‹)# GÃš# KÃ™-SIGâ‚â‚‡_', 'a-na _5(ğ’¹) Ë¡á¶¸Â²ÃRAD-MEÅ _ i-yu-ti-in _1(ğ’¹)-Ã€M_ áµá¶¸Ë¢á¶»na-da-tim# _2(ğ’¹)-Ã€M_ áµá¶¸Ë¢á¶»me-Å¡e-[ni]', 
 #               '_áµˆ#IÅ KUR#_', '_GÃš# [KÃ™]-BABBAR_ te-er-ha-at _DUMU-MUNUS_', '_INIM?-áµˆIÅ KUR#?_', 
 #               '[_ÃRAD_] [a]-bi-im _Uâ‚„ 6(ğ’¹)-KAM ZAL_-[ma]'])
 #       output = ATF.sumerianization(sign)
 #       self.maxDiff = None
 #       self.assertEqual(output, target)

if __name__ == '__main__':
    unittest.main()